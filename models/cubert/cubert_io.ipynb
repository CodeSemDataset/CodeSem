{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b325ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from csv import reader\n",
    "import glob\n",
    "import random\n",
    "\n",
    "maxInt = sys.maxsize\n",
    "while True:\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "\n",
    "equal_path = 'data/code_equal'\n",
    "not_equal_path = 'data/code_not_equal'\n",
    "\n",
    "equal_tsv = 'data/train_equal.tsv'\n",
    "not_equal_tsv = 'data/train_real_not_equal.tsv'\n",
    "fake_not_equal_tsv = 'data/train_fake_not_equal.tsv'\n",
    "\n",
    "combined_all_tsv = 'data/train_combined_all.tsv'\n",
    "combined_real_tsv = 'data/train_combined_real.tsv'\n",
    "combined_fake_tsv = 'data/train_combined_fake.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208bf063",
   "metadata": {},
   "source": [
    "## Equal Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3154917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_equal_size = 0\n",
    "equal_list = os.listdir(equal_path)\n",
    "with open(equal_tsv, 'w', newline='') as f_output:\n",
    "    tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "    tsv_output.writerow(['code_1', 'code_2', 'label'])\n",
    "    \n",
    "    for path in equal_list:\n",
    "      dir_path = equal_path + '/' + path + '/'\n",
    "      file_names = glob.glob(dir_path + \"*.c\")\n",
    "      file_1 = file_names[0]\n",
    "      file_2 = file_names[1]\n",
    "      with open(file_1, 'r') as code_1:\n",
    "        code_1 = code_1.read().replace('\\n', ' ').replace('\"','').replace('\\\\','')\n",
    "      with open(file_2, 'r') as code_2:\n",
    "        code_2 = code_2.read().replace('\\n', ' ').replace('\"','').replace('\\\\','')\n",
    "        \n",
    "      tsv_output.writerow([code_1, code_2, '1'])\n",
    "      train_equal_size += 1\n",
    "\n",
    "      if len(file_names) == 3:\n",
    "        file_3 = file_names[2]\n",
    "        \n",
    "        with open(file_3, 'r') as code_3:\n",
    "          code_3 = code_3.read().replace('\\n', ' ').replace('\"','').replace('\\\\','')\n",
    "          \n",
    "        tsv_output.writerow([code_1, code_3, '1'])\n",
    "        tsv_output.writerow([code_2, code_3, '1'])\n",
    "        train_equal_size += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed55dc",
   "metadata": {},
   "source": [
    "## Real Not-Equal Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27fad198",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_not_equal_size = 0\n",
    "not_equal_list = os.listdir(not_equal_path)   \n",
    "with open(not_equal_tsv, 'w', newline='') as f_output:\n",
    "    tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "    tsv_output.writerow(['code_1', 'code_2', 'label'])\n",
    "    \n",
    "    for path in not_equal_list:\n",
    "      dir_path = not_equal_path + '/' + path + '/'\n",
    "      file_names = glob.glob(dir_path + \"*.c\")\n",
    "      file_1 = file_names[0]\n",
    "      file_2 = file_names[1]      \n",
    "      with open(file_1, 'r') as code_1:\n",
    "        code_1 = code_1.read().replace('\\n', ' ').replace('\"','').replace('\\\\','')\n",
    "      with open(file_2, 'r') as code_2:\n",
    "        code_2 = code_2.read().replace('\\n', ' ').replace('\"','').replace('\\\\','')\n",
    "        \n",
    "      tsv_output.writerow([code_1, code_2, '0'])\n",
    "      train_not_equal_size += 1\n",
    "\n",
    "      if len(file_names) == 3:\n",
    "        file_3 = file_names[2]     \n",
    "        with open(file_3, 'r') as code_3:\n",
    "          code_3 = code_3.read().replace('\\n', ' ').replace('\"','').replace('\\\\','')\n",
    "          \n",
    "        tsv_output.writerow([code_1, code_3, '0'])\n",
    "        tsv_output.writerow([code_2, code_3, '0'])\n",
    "        train_not_equal_size += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa4788",
   "metadata": {},
   "source": [
    "## Fake Not-Equal Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d128441",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fake_not_equal_size = 0\n",
    "equal_list = os.listdir(equal_path)\n",
    "train_fake_not_equal_threshold = train_equal_size - train_not_equal_size\n",
    "\n",
    "with open(fake_not_equal_tsv, 'w', newline='') as f_output:\n",
    "    tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "    tsv_output.writerow(['code_1', 'code_2', 'label'])\n",
    "    \n",
    "    for i in range(len(equal_list)):\n",
    "      path_1 = equal_path + '/' + equal_list[i] + '/'\n",
    "      file_names = glob.glob(path_1 + \"*.c\")\n",
    "      file_1 = file_names[0]\n",
    "      with open(file_1, 'r') as code_1:\n",
    "        code_1 = code_1.read().replace('\\n', ' ').replace('\"','').replace('\\\\','')\n",
    "\n",
    "      for j in range(i+1, len(equal_list)):\n",
    "        if train_fake_not_equal_size < train_fake_not_equal_threshold:\n",
    "          path_2 = equal_path + '/' + equal_list[j] + '/'\n",
    "          file_names = glob.glob(path_2 + \"*.c\")\n",
    "          file_2 = file_names[0]   \n",
    "          with open(file_2, 'r') as code_2:\n",
    "            code_2 = code_2.read().replace('\\n', ' ').replace('\"','').replace('\\\\','')\n",
    "\n",
    "          tsv_output.writerow([code_1, code_2, '0'])\n",
    "          train_fake_not_equal_size += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a330e45f",
   "metadata": {},
   "source": [
    "## Combine all into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e26a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(combined_all_tsv, 'w', newline='') as f_output_1, open(combined_fake_tsv, 'w', newline='') as f_output_2, open(combined_real_tsv, 'w', newline='') as f_output_3:\n",
    "  tsv_output_1 = csv.writer(f_output_1, delimiter='\\t')\n",
    "  tsv_output_2 = csv.writer(f_output_2, delimiter='\\t')\n",
    "  tsv_output_3 = csv.writer(f_output_3, delimiter='\\t')\n",
    "  tsv_output_1.writerow(['code_1', 'code_2', 'label'])\n",
    "  tsv_output_2.writerow(['code_1', 'code_2', 'label'])\n",
    "  tsv_output_3.writerow(['code_1', 'code_2', 'label'])\n",
    "  \n",
    "  with open(equal_tsv, 'r') as f_input:   \n",
    "    tsv_reader = reader(f_input, delimiter='\\t')\n",
    "    header = next(tsv_reader)\n",
    "    if header != None:\n",
    "      count = 0\n",
    "      for row in tsv_reader:\n",
    "        tsv_output_1.writerow(row)\n",
    "        count += 1\n",
    "        if (count <= train_fake_not_equal_size):\n",
    "          tsv_output_2.writerow(row)\n",
    "        else:\n",
    "          tsv_output_3.writerow(row)\n",
    "  with open(not_equal_tsv, 'r') as f_input:   \n",
    "    tsv_reader = reader(f_input, delimiter='\\t')\n",
    "    header = next(tsv_reader)\n",
    "    if header != None:\n",
    "      for row in tsv_reader:\n",
    "        tsv_output_1.writerow(row)\n",
    "        tsv_output_3.writerow(row)\n",
    "  with open(fake_not_equal_tsv, 'r') as f_input:   \n",
    "    tsv_reader = reader(f_input, delimiter='\\t')\n",
    "    header = next(tsv_reader)\n",
    "    if header != None:\n",
    "      for row in tsv_reader:\n",
    "        tsv_output_1.writerow(row)\n",
    "        tsv_output_2.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c774a",
   "metadata": {},
   "source": [
    "## Shuffle & Divide Combined Dataset into Train/Dev/Test: 7/2/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83483428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_divide(fpath):\n",
    "  if (fpath == combined_fake_tsv):\n",
    "    outpath = 'data/dataset_fake/'\n",
    "  elif (fpath == combined_real_tsv):\n",
    "    outpath = 'data/dataset_real/'\n",
    "  else:\n",
    "    outpath = 'data/dataset_all/'\n",
    "\n",
    "  if not os.path.exists(os.path.dirname(outpath)):\n",
    "    try:\n",
    "      os.makedirs(os.path.dirname(outpath))\n",
    "    except OSError as exc:\n",
    "      if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "\n",
    "  with open(outpath+'train.tsv', 'w', newline='') as f_train, open(outpath+'dev.tsv', 'w', newline='') as f_dev, open(outpath+'test.tsv','w', newline='') as f_test:\n",
    "      tsv_train = csv.writer(f_train, delimiter='\\t')\n",
    "      tsv_dev = csv.writer(f_dev, delimiter='\\t')\n",
    "      tsv_test = csv.writer(f_test, delimiter='\\t')\n",
    "\n",
    "      tsv_train.writerow(['code_1', 'code_2', 'label'])\n",
    "      tsv_dev.writerow(['code_1', 'code_2', 'label'])\n",
    "      tsv_test.writerow(['code_1', 'code_2', 'label'])\n",
    "\n",
    "      fpath_shuffled = os.path.splitext(fpath)[0] + '_shuffled.tsv'\n",
    "      with open(fpath, 'r') as f_read:\n",
    "        data = f_read.readlines()\n",
    "        header, rows = data[0], data[1:]\n",
    "        random.shuffle(rows)\n",
    "      with open(fpath_shuffled ,'w') as f_write:\n",
    "        f_write.write(''.join([header]+rows))\n",
    "      \n",
    "      with open(fpath_shuffled, 'r') as f_combined, open(outpath+'test_labels.txt' ,'w') as f_labels:\n",
    "        tsv_reader = reader(f_combined, delimiter='\\t')\n",
    "        header = next(tsv_reader)\n",
    "        if header != None:\n",
    "          i = 0\n",
    "          for row in tsv_reader:\n",
    "            if i <= 0.7 * len(rows):\n",
    "              tsv_train.writerow(row)\n",
    "            elif i <= 0.9 * len(rows):\n",
    "              tsv_dev.writerow(row)\n",
    "            else:\n",
    "              tsv_test.writerow(row)\n",
    "              f_labels.write(row[-1] + ' ')\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2a4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [combined_all_tsv, combined_real_tsv, combined_fake_tsv]:\n",
    "  shuffle_and_divide(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERT",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
