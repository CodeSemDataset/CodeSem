{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b325ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from csv import reader\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "include_folders = ['gcc', 'linux', 'mysql']\n",
    "\n",
    "dir_name = '/home/shared/PLDI21_model'\n",
    "dataset_path = '../datasets/functionally-equiv-compilable/'\n",
    "map_path = 'data/equal/path2tokens.tsv'\n",
    "\n",
    "equal_tsv = 'data/equal/path_train_eq.tsv'\n",
    "ne_1_tsv = 'data/equal/path_train_ne_1.tsv'\n",
    "ne_2_tsv = 'data/equal/path_train_ne_2.tsv'\n",
    "\n",
    "id_equal_tsv = 'data/equal/token_train_eq.tsv'\n",
    "id_ne_1_tsv = 'data/equal/token_train_ne_1.tsv'\n",
    "id_ne_2_tsv = 'data/equal/token_train_ne_2.tsv'\n",
    "\n",
    "combined_eq_ne_1_tsv = 'data/equal/combined_eq_ne_1.tsv'\n",
    "combined_eq_ne_2_tsv = 'data/equal/combined_eq_ne_2.tsv'\n",
    "\n",
    "ratio_eq_ne_1_tsv = 'data/equal/ratio_eq_ne_1.tsv'\n",
    "ratio_eq_ne_2_tsv = 'data/equal/ratio_eq_ne_2.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efa648",
   "metadata": {},
   "source": [
    "## Replace Path by Token Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f985b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsv size: 2596\n"
     ]
    }
   ],
   "source": [
    "path_map = {}\n",
    "with open(map_path, 'r') as f_input:   \n",
    "    tsv_reader = reader(f_input, delimiter='\\t')\n",
    "    header = next(tsv_reader)\n",
    "    if header != None:\n",
    "      for row in tsv_reader:\n",
    "        path_map[row[0]] = row[1]\n",
    "print('tsv size:', len(path_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b74f27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file count: 2596\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "dirs = [os.path.join(dataset_path, o) for o in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path,o)) \\\n",
    "        and o in include_folders]\n",
    "for dir in dirs:\n",
    "      sub_dirs =  [os.path.join(dir, o) for o in os.listdir(dir) if o != 'include']\n",
    "      for sub_dir in sub_dirs:\n",
    "          sub_subdirs = [os.path.join(sub_dir, o) for o in os.listdir(sub_dir)]\n",
    "          for sub_subdir in sub_subdirs:\n",
    "              files = glob.glob(sub_subdir + '/*.c')\n",
    "              count += len(files)\n",
    "print('file count:', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a25ef",
   "metadata": {},
   "source": [
    "## R/W EQ examples into TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6791a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_equal_size: 1114\n"
     ]
    }
   ],
   "source": [
    "train_equal_size = 0\n",
    "with open(equal_tsv, 'w', newline='') as f_output, open(id_equal_tsv, 'w', newline='') as id_output:\n",
    "    tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "    tsv_output.writerow(['file_1', 'file_2', 'label'])\n",
    "    \n",
    "    id_output = csv.writer(id_output, delimiter='\\t')\n",
    "    id_output.writerow(['id_1', 'id_2', 'label'])\n",
    "\n",
    "    dirs = [os.path.join(dataset_path, o) for o in os.listdir(dataset_path) \n",
    "                        if os.path.isdir(os.path.join(dataset_path,o)) and o in include_folders]\n",
    "    for dir in dirs:\n",
    "        eq_dirs =  [os.path.join(dir, o) for o in os.listdir(dir) if '_eq'in o]\n",
    "        for eq_dir in eq_dirs:\n",
    "            eq_subdirs = [os.path.join(eq_dir, o) for o in os.listdir(eq_dir)]\n",
    "            for eq_subdir in eq_subdirs:\n",
    "                files = glob.glob(eq_subdir + '/*.c')\n",
    "                pairs = list(itertools.combinations(files, 2))\n",
    "                for pair in pairs:\n",
    "                    file_1 = pair[0].replace('..', dir_name).replace('\\\\', '/')\n",
    "                    file_2 = pair[1].replace('..', dir_name).replace('\\\\', '/')\n",
    "                    id_1 = path_map[file_1]\n",
    "                    id_2 = path_map[file_2]\n",
    "                    tsv_output.writerow([file_1, file_2, '1'])\n",
    "                    id_output.writerow([id_1, id_2, '1'])\n",
    "                    train_equal_size += 1\n",
    "print('train_equal_size:', train_equal_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10a3ce7",
   "metadata": {},
   "source": [
    "## R/W NE_1 examples into TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e77123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ne1_size: 2553\n"
     ]
    }
   ],
   "source": [
    "train_ne1_size = 0\n",
    "with open(ne_1_tsv, 'w', newline='') as f_output, open(id_ne_1_tsv, 'w', newline='') as id_output:\n",
    "    tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "    tsv_output.writerow(['file_1', 'file_2', 'label'])\n",
    "    \n",
    "    id_output = csv.writer(id_output, delimiter='\\t')\n",
    "    id_output.writerow(['id_1', 'id_2', 'label'])\n",
    "\n",
    "    dirs = [os.path.join(dataset_path, o) for o in os.listdir(dataset_path) \n",
    "                            if os.path.isdir(os.path.join(dataset_path,o)) and o in include_folders]\n",
    "    for dir in dirs:\n",
    "        eq_dirs = [os.path.join(dir, o) for o in os.listdir(dir) if '_eq'in o]\n",
    "        ne_dirs = [os.path.join(dir, o) for o in os.listdir(dir) if '_ne_1'in o]\n",
    "        for ne_dir in ne_dirs:\n",
    "            ne_subdirs = [os.path.join(ne_dir, o) for o in os.listdir(ne_dir)]\n",
    "            for ne_subdir in ne_subdirs:\n",
    "                ne_files = glob.glob(ne_subdir + '/*.c')\n",
    "                ne_subdir_name = ne_subdir.split('\\\\')[-1]\n",
    "                for eq_dir in eq_dirs:\n",
    "                  eq_subdir = [os.path.join(eq_dir, o) for o in os.listdir(eq_dir) if ne_subdir_name in o][0]\n",
    "                eq_files = glob.glob(eq_subdir + '/*.c')\n",
    "                for ne_file in ne_files:\n",
    "                  for eq_file in eq_files:\n",
    "                    file_1 = ne_file.replace('..', dir_name).replace('\\\\', '/')\n",
    "                    file_2 = eq_file.replace('..', dir_name).replace('\\\\', '/')\n",
    "                    id_1 = path_map[file_1]\n",
    "                    id_2 = path_map[file_2]\n",
    "                    tsv_output.writerow([file_1, file_2, '0'])\n",
    "                    id_output.writerow([id_1, id_2, '0'])\n",
    "                    train_ne1_size += 1\n",
    "print('train_ne1_size:', train_ne1_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7305c",
   "metadata": {},
   "source": [
    "## R/W NE_2 examples into TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ffeac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ne2_size: 1227\n"
     ]
    }
   ],
   "source": [
    "train_ne2_size = 0\n",
    "with open(ne_2_tsv, 'w', newline='') as f_output, open(id_ne_2_tsv, 'w', newline='') as id_output:\n",
    "    tsv_output = csv.writer(f_output, delimiter='\\t')\n",
    "    tsv_output.writerow(['file_1', 'file_2', 'label'])\n",
    "    \n",
    "    id_output = csv.writer(id_output, delimiter='\\t')\n",
    "    id_output.writerow(['id_1', 'id_2', 'label'])\n",
    "    \n",
    "    dirs = [os.path.join(dataset_path, o) for o in os.listdir(dataset_path) \n",
    "                            if os.path.isdir(os.path.join(dataset_path,o)) and o in include_folders]\n",
    "    for dir in dirs:\n",
    "        eq_dirs = [os.path.join(dir, o) for o in os.listdir(dir) if '_eq'in o]\n",
    "        ne_dirs = [os.path.join(dir, o) for o in os.listdir(dir) if '_ne_2'in o]\n",
    "        for ne_dir in ne_dirs:\n",
    "            ne_subdirs = [os.path.join(ne_dir, o) for o in os.listdir(ne_dir)]\n",
    "            for ne_subdir in ne_subdirs:\n",
    "                ne_files = glob.glob(ne_subdir + '/*.c')\n",
    "                ne_subdir_name = ne_subdir.split('\\\\')[-1]\n",
    "                for eq_dir in eq_dirs:\n",
    "                  eq_subdir = [os.path.join(eq_dir, o) for o in os.listdir(eq_dir) if ne_subdir_name in o][0]\n",
    "                eq_files = glob.glob(eq_subdir + '/*.c')\n",
    "                for ne_file in ne_files:\n",
    "                  for eq_file in eq_files:\n",
    "                    file_1 = ne_file.replace('..', dir_name).replace('\\\\', '/')\n",
    "                    file_2 = eq_file.replace('..', dir_name).replace('\\\\', '/')\n",
    "                    id_1 = path_map[file_1]\n",
    "                    id_2 = path_map[file_2]\n",
    "                    tsv_output.writerow([file_1, file_2, '0'])\n",
    "                    id_output.writerow([id_1, id_2, '0'])\n",
    "                    train_ne2_size += 1\n",
    "print('train_ne2_size:', train_ne2_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305911c",
   "metadata": {},
   "source": [
    "## All combined datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7106a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(combined_eq_ne_1_tsv, 'w', newline='') as f_ne_1, open(combined_eq_ne_2_tsv, 'w', newline='') as f_ne_2:\n",
    "  tsv_output_1 = csv.writer(f_ne_1, delimiter='\\t')\n",
    "  tsv_output_2 = csv.writer(f_ne_2, delimiter='\\t')\n",
    "  \n",
    "  tsv_output_1.writerow(['code_1', 'code_2', 'label'])\n",
    "  tsv_output_2.writerow(['code_1', 'code_2', 'label'])\n",
    " \n",
    "  with open(id_equal_tsv, 'r') as f_input:   \n",
    "    tsv_reader = reader(f_input, delimiter='\\t')\n",
    "    header = next(tsv_reader)\n",
    "    if header != None:\n",
    "      for row in tsv_reader:\n",
    "        tsv_output_1.writerow(row)\n",
    "        tsv_output_2.writerow(row)\n",
    "        \n",
    "  with open(id_ne_1_tsv, 'r') as f_input:   \n",
    "    tsv_reader = reader(f_input, delimiter='\\t')\n",
    "    header = next(tsv_reader)\n",
    "    if header != None:\n",
    "      for row in tsv_reader:\n",
    "        tsv_output_1.writerow(row)\n",
    "        \n",
    "  with open(id_ne_2_tsv, 'r') as f_input:   \n",
    "    tsv_reader = reader(f_input, delimiter='\\t')\n",
    "    header = next(tsv_reader)\n",
    "    if header != None:\n",
    "      for row in tsv_reader:\n",
    "        tsv_output_2.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb838fd",
   "metadata": {},
   "source": [
    "## 1:1 ratio datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8d8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ratio_eq_ne_1_tsv, 'w', newline='') as f_ne_1, open(ratio_eq_ne_2_tsv, 'w', newline='') as f_ne_2:\n",
    "  tsv_output_1 = csv.writer(f_ne_1, delimiter='\\t')\n",
    "  tsv_output_2 = csv.writer(f_ne_2, delimiter='\\t')\n",
    "  \n",
    "  tsv_output_1.writerow(['code_1', 'code_2', 'label'])\n",
    "  tsv_output_2.writerow(['code_1', 'code_2', 'label'])\n",
    " \n",
    "  with open(id_equal_tsv, 'r') as f_input:   \n",
    "    tsv_reader = reader(f_input, delimiter='\\t')\n",
    "    header = next(tsv_reader)\n",
    "    if header != None:\n",
    "      count = 0\n",
    "      for row in tsv_reader:\n",
    "        if count < train_equal_size:\n",
    "          tsv_output_1.writerow(row)\n",
    "          tsv_output_2.writerow(row)\n",
    "          count += 1\n",
    "        \n",
    "  with open(id_ne_1_tsv, 'r') as f_input:   \n",
    "    tsv_reader = reader(f_input, delimiter='\\t')\n",
    "    header = next(tsv_reader)\n",
    "    if header != None:\n",
    "      count = 0\n",
    "      for row in tsv_reader:\n",
    "        if count < train_equal_size:\n",
    "          tsv_output_1.writerow(row)\n",
    "          count += 1\n",
    "        \n",
    "  with open(id_ne_2_tsv, 'r') as f_input:   \n",
    "    tsv_reader = reader(f_input, delimiter='\\t')\n",
    "    header = next(tsv_reader)\n",
    "    if header != None:\n",
    "      count = 0\n",
    "      for row in tsv_reader:\n",
    "        if count < train_equal_size:\n",
    "          tsv_output_2.writerow(row)\n",
    "          count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c774a",
   "metadata": {},
   "source": [
    "## Shuffle & Divide Dataset into Train/Dev/Test: 7/1.5/1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83483428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_divide(fpath):\n",
    "  if (fpath == combined_eq_ne_1_tsv):\n",
    "    outpath = 'data/equal/equal_dataset_combined_1/'\n",
    "  elif (fpath == combined_eq_ne_2_tsv):\n",
    "    outpath = 'data/equal/equal_dataset_combined_2/'\n",
    "  elif (fpath == ratio_eq_ne_1_tsv):\n",
    "    outpath = 'data/equal/equal_dataset_ratio_1/'\n",
    "  else:\n",
    "    outpath = 'data/equal/equal_dataset_ratio_2/'\n",
    "\n",
    "  if not os.path.exists(os.path.dirname(outpath)):\n",
    "    try:\n",
    "      os.makedirs(os.path.dirname(outpath))\n",
    "    except OSError as exc:\n",
    "      if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "\n",
    "  with open(outpath+'train.tsv', 'w', newline='') as f_train, open(outpath+'dev.tsv', 'w', newline='') as f_dev, open(outpath+'test.tsv','w', newline='') as f_test:\n",
    "      tsv_train = csv.writer(f_train, delimiter='\\t')\n",
    "      tsv_dev = csv.writer(f_dev, delimiter='\\t')\n",
    "      tsv_test = csv.writer(f_test, delimiter='\\t')\n",
    "\n",
    "      tsv_train.writerow(['code_1', 'code_2', 'label'])\n",
    "      tsv_dev.writerow(['code_1', 'code_2', 'label'])\n",
    "      tsv_test.writerow(['code_1', 'code_2', 'label'])\n",
    "\n",
    "      fpath_shuffled = os.path.splitext(fpath)[0] + '_shuffled.tsv'\n",
    "      with open(fpath, 'r') as f_read:\n",
    "        data = f_read.readlines()\n",
    "        header, rows = data[0], data[1:]\n",
    "        random.shuffle(rows)\n",
    "      with open(fpath_shuffled ,'w') as f_write:\n",
    "        f_write.write(''.join([header]+rows))\n",
    "      \n",
    "      with open(fpath_shuffled, 'r') as f_combined, open(outpath+'test_labels.txt' ,'w') as f_labels:\n",
    "        tsv_reader = reader(f_combined, delimiter='\\t')\n",
    "        header = next(tsv_reader)\n",
    "        if header != None:\n",
    "          i = 0\n",
    "          for row in tsv_reader:\n",
    "            if i <= 0.7 * len(rows):\n",
    "              tsv_train.writerow(row)\n",
    "            elif i <= 0.85 * len(rows):\n",
    "              tsv_dev.writerow(row)\n",
    "            else:\n",
    "              tsv_test.writerow(row)\n",
    "              f_labels.write(row[-1] + ' ')\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2a4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [combined_eq_ne_1_tsv, combined_eq_ne_2_tsv, ratio_eq_ne_1_tsv, ratio_eq_ne_2_tsv]:\n",
    "  shuffle_and_divide(file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15a9e0e59084761089efa70f1417557ef1c600e614b56883785c3d0a2da2f962"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
